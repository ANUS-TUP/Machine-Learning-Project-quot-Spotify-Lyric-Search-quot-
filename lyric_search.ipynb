{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421ddff9-1eab-4234-ba54-e7d3502dd54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.13.6 (tags/v3.13.6:4e66535, Aug  6 2025, 14:36:00) [MSC v.1944 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71faaf74-eb10-4278-b839-0e3a4a0a1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\anustupdas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2e647b-5a4f-45e5-b899-421442be5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0696bde5-4fc3-43c9-a040-b2eab846f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1ad977-1010-41de-a115-fc624074e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbc13a1-567c-4a81-853d-90752fb1158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANUSTUPDAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ANUSTUPDAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4c1254-c0ea-4c6c-b672-9b916359ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Spotify_Song_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ffceda-942c-468f-857b-0204650bdc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'song', 'link', 'text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164d890e-0409-4484-b9c9-7c735331769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = text.split()   # ğŸ”¥ safer than word_tokenize\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb2b6be-5979-47a8-8905-da63007f83c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "      <td>look face wonderful face means something speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "      <td>take easy please touch gently like summer even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "      <td>ill never know go put lousy rotten show boy to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Look at her face, it's a wonderful face  \\nAnd...   \n",
       "1  Take it easy with me, please  \\nTouch me gentl...   \n",
       "2  I'll never know why I had to go  \\nWhy I had t...   \n",
       "3  Making somebody happy is a question of give an...   \n",
       "4  Making somebody happy is a question of give an...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  look face wonderful face means something speci...  \n",
       "1  take easy please touch gently like summer even...  \n",
       "2  ill never know go put lousy rotten show boy to...  \n",
       "3  making somebody happy question give take learn...  \n",
       "4  making somebody happy question give take learn...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "df[['text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2697273a-5a70-4517-b527-97179324f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['song'] + \" - \" + df['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb9aac6-a235-4cad-b154-5fe3db791a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a043777c-145c-47fe-9fc5-68da0a10bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "X = tfidf.fit_transform(df['cleaned_text']).toarray()\n",
    "y = df['label_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1bad8c-94a0-44a6-8a80-597c0c144e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3beaf1c0-149f-4ef3-a290-34b64f97e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANUSTUPDAS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(df['label_encoded'].unique()), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006e7a05-5be1-47c6-a4f0-387373139557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a60a10-166a-43c5-bf34-c69493791c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 294ms/step - accuracy: 0.0000e+00 - loss: 11.0440 - val_accuracy: 0.0000e+00 - val_loss: 11.1898\n",
      "Epoch 2/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 285ms/step - accuracy: 0.0000e+00 - loss: 10.8574 - val_accuracy: 0.0000e+00 - val_loss: 11.6087\n",
      "Epoch 3/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 295ms/step - accuracy: 7.2275e-05 - loss: 10.7741 - val_accuracy: 0.0000e+00 - val_loss: 11.9734\n",
      "Epoch 4/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 293ms/step - accuracy: 2.1683e-04 - loss: 10.5669 - val_accuracy: 0.0000e+00 - val_loss: 12.2869\n",
      "Epoch 5/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 278ms/step - accuracy: 0.0016 - loss: 9.9798 - val_accuracy: 0.0000e+00 - val_loss: 12.6962\n",
      "Epoch 6/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 300ms/step - accuracy: 0.0082 - loss: 9.0452 - val_accuracy: 0.0000e+00 - val_loss: 13.3109\n",
      "Epoch 7/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 295ms/step - accuracy: 0.0300 - loss: 7.8791 - val_accuracy: 0.0000e+00 - val_loss: 14.1507\n",
      "Epoch 8/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 293ms/step - accuracy: 0.0811 - loss: 6.5808 - val_accuracy: 2.1683e-04 - val_loss: 14.6874\n",
      "Epoch 9/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 287ms/step - accuracy: 0.1587 - loss: 5.3774 - val_accuracy: 2.1683e-04 - val_loss: 15.3066\n",
      "Epoch 10/10\n",
      "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 296ms/step - accuracy: 0.2567 - loss: 4.3475 - val_accuracy: 2.1683e-04 - val_loss: 16.1915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14eeafd4-cba6-4322-94f8-3e7c1ed92826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_song_artist(input_text):\n",
    "    cleaned = preprocess_text(input_text)\n",
    "    vector = tfidf.transform([cleaned]).toarray()\n",
    "    \n",
    "    prediction = model.predict(vector)\n",
    "    predicted_index = prediction.argmax()\n",
    "    \n",
    "    return label_encoder.inverse_transform([predicted_index])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8acd79-e44e-48b3-b648-b342744e84bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted Song & Artist: It's So Easy (To Fall In Love) - Linda Ronstadt\n"
     ]
    }
   ],
   "source": [
    "test_lyrics = \"Take it easy with me, please\"\n",
    "\n",
    "prediction = predict_song_artist(test_lyrics)\n",
    "print(\"Predicted Song & Artist:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ed648-edd4-4ae1-92a5-8fba458534ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
